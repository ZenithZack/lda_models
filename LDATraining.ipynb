{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDATraining.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbacoP8YqKQBDUGh0VIe1G",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZenithZack/lda_models/blob/main/LDATraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF8CRj3Qm-uz"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "sPq7o3aqo7iO",
        "outputId": "2b12b331-48d0-4d43-b732-6450717af08f"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6051a377-cbac-4774-8384-4d54a78e96cd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6051a377-cbac-4774-8384-4d54a78e96cd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSuTkLYSoUKx"
      },
      "source": [
        "data = pd.read_csv('/content/abcnews-date-text.csv', error_bad_lines=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayB6489DqG5P"
      },
      "source": [
        "data_text = data[['headline_text']]\n",
        "#print(type(data_text))\n",
        "#print(data_text)\n",
        "data_text['index'] = data_text.index\n",
        "documents = data_text\n",
        "#print(type(documents))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8gkB-KJrne8",
        "outputId": "471a81b8-e574-4863-bc68-2ba4ad25dfcd"
      },
      "source": [
        "print(len(documents))\n",
        "print(documents[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127958\n",
            "                                       headline_text  index\n",
            "0  aba decides against community broadcasting lic...      0\n",
            "1     act fire witnesses must be aware of defamation      1\n",
            "2     a g calls for infrastructure protection summit      2\n",
            "3           air nz staff in aust strike for pay rise      3\n",
            "4      air nz strike to affect australian travellers      4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTraoQbts24t",
        "outputId": "42cfb628-cce2-4da0-eb7c-2440de7378b7"
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(2018)\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6wUKAY1uiuM"
      },
      "source": [
        "# Stemmer is an object and stem is a function (Stemming is carried out). The stem basically takes string as argument\n",
        "# Had to find the right stemmer class on basis of the number of positional arguments\n",
        "def lemmatize_stemming(text):\n",
        "  return PorterStemmer().stem(WordNetLemmatizer().lemmatize(text, pos='v'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQc94y3KzLhd"
      },
      "source": [
        "def preprocess(text):\n",
        "  result = []\n",
        "  for token in gensim.utils.simple_preprocess(text):\n",
        "    if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "      result.append(lemmatize_stemming(token))\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTh42-NEz1cu",
        "outputId": "16e64f99-7682-4d82-fb7e-19ff7a746b7a"
      },
      "source": [
        "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
        "print(type(doc_sample))\n",
        "print(doc_sample)\n",
        "\n",
        "print('original document: ')\n",
        "words = []\n",
        "for word in doc_sample.split(' '):\n",
        "  words.append(word)\n",
        "print(words)\n",
        "print('\\n\\n tokenized and lemmatized document: ')\n",
        "print(preprocess(doc_sample))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n",
            "ratepayers group wants compulsory local govt voting\n",
            "original document: \n",
            "['ratepayers', 'group', 'wants', 'compulsory', 'local', 'govt', 'voting']\n",
            "\n",
            "\n",
            " tokenized and lemmatized document: \n",
            "['ratepay', 'group', 'want', 'compulsori', 'local', 'govt', 'vote']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RktER7Mc4PyR"
      },
      "source": [
        "documents = documents.dropna(subset=['headline_text'])\n",
        "processed_docs = documents['headline_text'].map(preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26dWHj3h78mT",
        "outputId": "a136bc39-8570-4dbf-8f2d-431687724402"
      },
      "source": [
        "processed_docs[:4311]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                      [decid, commun, broadcast, licenc]\n",
              "1                                      [wit, awar, defam]\n",
              "2                  [call, infrastructur, protect, summit]\n",
              "3                             [staff, aust, strike, rise]\n",
              "4                    [strike, affect, australian, travel]\n",
              "                              ...                        \n",
              "4306                          [queensland, cyclon, watch]\n",
              "4307                                [question, rais, gmo]\n",
              "4308                        [rain, hamper, goat, product]\n",
              "4309                        [rain, help, dampen, bushfir]\n",
              "4310    [ratepay, group, want, compulsori, local, govt...\n",
              "Name: headline_text, Length: 4311, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35oIyEIK7fHV",
        "outputId": "cc40929c-e8e8-4649-f2fe-160cf605e4ae"
      },
      "source": [
        "# Here the argument 'preprocessed_docs' is a 'list of lists'\n",
        "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
        "\n",
        "count = 0\n",
        "# print(len(dictionary.keys()))\n",
        "for k, v in dictionary.iteritems():\n",
        "  print(k, v)\n",
        "  count += 1\n",
        "  if count > 5:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 broadcast\n",
            "1 commun\n",
            "2 decid\n",
            "3 licenc\n",
            "4 awar\n",
            "5 defam\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fe2aO69bTA8"
      },
      "source": [
        "dictionary.filter_extremes(no_below = 15, no_above = 0.5, keep_n = 100000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arvQPM2giTZM",
        "outputId": "a23c3728-1602-4b46-faea-ae43d754053a"
      },
      "source": [
        "# Extra lines of code for generating N-grams\n",
        "from gensim.models.phrases import Phraser, Phrases\n",
        "bigram = Phrases(processed_docs, min_count = 1,threshold = 100)\n",
        "trigrams = Phrases(bigram[processed_docs], min_count = 5, threshold = 100)\n",
        "print(bigram[processed_docs[0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['decid', 'commun', 'broadcast', 'licenc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4qQ1SwxkeFN",
        "outputId": "7fc5fa3a-f00e-455e-dbc4-f6e3a4167030"
      },
      "source": [
        "# Continued implementation of above (to save on RAM)\n",
        "print(trigrams[processed_docs[5]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ambiti', 'olsson', 'win', 'tripl', 'jump']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V40fwkuig5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e14548aa-91d8-4342-e713-60b985030c5c"
      },
      "source": [
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "bow_corpus[4309]\n",
        "#bow_doc_4310 = bow_corpus[4310]\n",
        "#for i in range(len(bow_doc_4310)):\n",
        "    #print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
        "                                               #dictionary[bow_doc_4310[i][0]], \n",
        "#bow_doc_4310[i][1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(68, 1), (102, 1), (443, 1), (2997, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkbJ3vU-tiEW",
        "outputId": "9d9b24bd-638a-4825-a97b-77e55c5e9083"
      },
      "source": [
        "from gensim import corpora, models\n",
        "\n",
        "tfidf = models.TfidfModel(bow_corpus)\n",
        "#print(tfidf)\n",
        "corpus_tfidf = tfidf[bow_corpus]\n",
        "print(corpus_tfidf)\n",
        "from pprint import pprint\n",
        "\n",
        "for doc in corpus_tfidf:\n",
        "  pprint(doc)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<gensim.interfaces.TransformedCorpus object at 0x7f98ed664390>\n",
            "[(0, 0.5871107924946463),\n",
            " (1, 0.39059932887674903),\n",
            " (2, 0.4897672242374202),\n",
            " (3, 0.5126998612054761)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGAAIhq00qCM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "outputId": "021946e8-23e0-4477-a3dc-9de17500d248"
      },
      "source": [
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-1:\n",
            "Process ForkPoolWorker-2:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\", line 333, in worker_e_step\n",
            "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\", line 333, in worker_e_step\n",
            "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 725, in do_estep\n",
            "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 725, in do_estep\n",
            "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 676, in inference\n",
            "    gammad = self.alpha + expElogthetad * np.dot(cts / phinorm, expElogbetad.T)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 690, in inference\n",
            "    sstats[:, ids] += np.outer(expElogthetad.T, cts / phinorm)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFull\u001b[0m                                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    287\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                         \u001b[0mjob_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m                         \u001b[0mchunk_put\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(self, obj, block, timeout)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFull\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFull\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-51e139e865c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlda_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMulticore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    297\u001b[0m                         \u001b[0;31m# in case the input job queue is full, keep clearing the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                         \u001b[0;31m# result queue, to make sure we don't deadlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                         \u001b[0mprocess_result_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0mprocess_result_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mprocess_result_queue\u001b[0;34m(force)\u001b[0m\n\u001b[1;32m    276\u001b[0m                             ((force and queue_size[0] == 0) or\n\u001b[1;32m    277\u001b[0m                                  (self.eval_every != 0 and (self.num_updates / updateafter) % self.eval_every == 0)):\n\u001b[0;32m--> 278\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_docs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlencorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0mchunk_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mlog_perplexity\u001b[0;34m(self, chunk, total_docs)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0mcorpus_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0msubsample_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal_docs\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0mperwordbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubsample_ratio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msubsample_ratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorpus_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m         logger.info(\n\u001b[1;32m    806\u001b[0m             \u001b[0;34m\"%.3f per-word bound, %.1f perplexity estimate based on a held-out corpus of %i documents with %i words\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mbound\u001b[0;34m(self, corpus, gamma, subsample_ratio)\u001b[0m\n\u001b[1;32m   1066\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bound: at document #%i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m                 \u001b[0mgammad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                 \u001b[0mgammad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0mElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElogtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0mexpElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpElogtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0mexpElogbetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpElogbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;31m# The optimal phi_{dwk} is proportional to expElogthetad_k * expElogbetad_w.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvJv8XwRyLRJ",
        "outputId": "73342d4b-f699-4c0f-9a15-a965a53ee8f5"
      },
      "source": [
        "for idx, topic in lda_model.print_topics(-1):\n",
        "  print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Words: 0.061*\"polic\" + 0.029*\"kill\" + 0.024*\"crash\" + 0.018*\"death\" + 0.016*\"investig\" + 0.016*\"miss\" + 0.016*\"attack\" + 0.015*\"probe\" + 0.013*\"bomb\" + 0.012*\"search\"\n",
            "Topic: 1 \n",
            "Words: 0.020*\"rise\" + 0.019*\"price\" + 0.018*\"say\" + 0.017*\"govt\" + 0.017*\"health\" + 0.014*\"farmer\" + 0.012*\"fund\" + 0.011*\"hospit\" + 0.011*\"fuel\" + 0.010*\"flood\"\n",
            "Topic: 2 \n",
            "Words: 0.027*\"plan\" + 0.017*\"nation\" + 0.016*\"urg\" + 0.016*\"hous\" + 0.015*\"public\" + 0.015*\"elect\" + 0.015*\"power\" + 0.014*\"continu\" + 0.014*\"govt\" + 0.013*\"council\"\n",
            "Topic: 3 \n",
            "Words: 0.018*\"concern\" + 0.017*\"govt\" + 0.016*\"protest\" + 0.015*\"school\" + 0.014*\"labor\" + 0.013*\"union\" + 0.012*\"defend\" + 0.010*\"inquiri\" + 0.010*\"bird\" + 0.010*\"plan\"\n",
            "Topic: 4 \n",
            "Words: 0.023*\"fear\" + 0.017*\"push\" + 0.015*\"break\" + 0.014*\"worker\" + 0.014*\"famili\" + 0.013*\"fish\" + 0.012*\"telstra\" + 0.011*\"sale\" + 0.010*\"feder\" + 0.010*\"govt\"\n",
            "Topic: 5 \n",
            "Words: 0.015*\"coast\" + 0.015*\"year\" + 0.014*\"gold\" + 0.014*\"market\" + 0.013*\"open\" + 0.013*\"record\" + 0.010*\"world\" + 0.010*\"miner\" + 0.010*\"close\" + 0.010*\"storm\"\n",
            "Topic: 6 \n",
            "Words: 0.036*\"charg\" + 0.034*\"court\" + 0.032*\"face\" + 0.021*\"accus\" + 0.020*\"jail\" + 0.017*\"murder\" + 0.016*\"drug\" + 0.016*\"case\" + 0.013*\"trial\" + 0.013*\"terror\"\n",
            "Topic: 7 \n",
            "Words: 0.034*\"council\" + 0.024*\"water\" + 0.021*\"boost\" + 0.017*\"plan\" + 0.014*\"offer\" + 0.012*\"fund\" + 0.012*\"chang\" + 0.012*\"govt\" + 0.010*\"delay\" + 0.010*\"welcom\"\n",
            "Topic: 8 \n",
            "Words: 0.015*\"test\" + 0.014*\"win\" + 0.013*\"south\" + 0.012*\"australia\" + 0.012*\"lead\" + 0.010*\"clash\" + 0.010*\"commun\" + 0.010*\"final\" + 0.010*\"victori\" + 0.009*\"damag\"\n",
            "Topic: 9 \n",
            "Words: 0.018*\"home\" + 0.017*\"talk\" + 0.017*\"deal\" + 0.013*\"lose\" + 0.012*\"iraq\" + 0.012*\"north\" + 0.010*\"trade\" + 0.010*\"aust\" + 0.009*\"grower\" + 0.009*\"blue\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BKNuBfw9jAj"
      },
      "source": [
        "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=20, id2word=dictionary, passes=2, workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xelDh_hN-srp",
        "outputId": "88cbffd6-8ae8-47ea-bc6b-8dc8ad9524c7"
      },
      "source": [
        "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
        "  print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Words: 0.011*\"east\" + 0.010*\"benefit\" + 0.010*\"violenc\" + 0.008*\"stab\" + 0.007*\"evacu\" + 0.006*\"wood\" + 0.006*\"eagl\" + 0.006*\"leak\" + 0.006*\"timor\" + 0.005*\"dog\"\n",
            "Topic: 1 \n",
            "Words: 0.015*\"terror\" + 0.011*\"plane\" + 0.010*\"whale\" + 0.008*\"nurs\" + 0.008*\"corbi\" + 0.008*\"number\" + 0.007*\"address\" + 0.007*\"crash\" + 0.007*\"anti\" + 0.007*\"light\"\n",
            "Topic: 2 \n",
            "Words: 0.016*\"bird\" + 0.011*\"doubt\" + 0.007*\"alcohol\" + 0.007*\"pacif\" + 0.007*\"medic\" + 0.006*\"mix\" + 0.006*\"south\" + 0.006*\"africa\" + 0.006*\"expans\" + 0.006*\"chelsea\"\n",
            "Topic: 3 \n",
            "Words: 0.017*\"toll\" + 0.015*\"kill\" + 0.010*\"death\" + 0.009*\"bomb\" + 0.009*\"road\" + 0.009*\"suicid\" + 0.008*\"escap\" + 0.008*\"blast\" + 0.007*\"accid\" + 0.007*\"hurt\"\n",
            "Topic: 4 \n",
            "Words: 0.013*\"drive\" + 0.012*\"drink\" + 0.008*\"retir\" + 0.008*\"hostag\" + 0.007*\"coal\" + 0.007*\"driver\" + 0.006*\"energi\" + 0.006*\"patient\" + 0.006*\"young\" + 0.006*\"polic\"\n",
            "Topic: 5 \n",
            "Words: 0.018*\"price\" + 0.011*\"fuel\" + 0.010*\"market\" + 0.008*\"stock\" + 0.008*\"lion\" + 0.007*\"petrol\" + 0.007*\"high\" + 0.007*\"seri\" + 0.006*\"wallabi\" + 0.006*\"resourc\"\n",
            "Topic: 6 \n",
            "Words: 0.009*\"uranium\" + 0.008*\"crop\" + 0.008*\"firefight\" + 0.008*\"immigr\" + 0.008*\"rethink\" + 0.007*\"raid\" + 0.007*\"christma\" + 0.007*\"travel\" + 0.007*\"import\" + 0.006*\"pope\"\n",
            "Topic: 7 \n",
            "Words: 0.008*\"arriv\" + 0.007*\"pont\" + 0.007*\"cole\" + 0.007*\"fraud\" + 0.006*\"russia\" + 0.006*\"restrict\" + 0.006*\"halt\" + 0.006*\"jackson\" + 0.006*\"hick\" + 0.005*\"guard\"\n",
            "Topic: 8 \n",
            "Words: 0.016*\"closer\" + 0.011*\"teacher\" + 0.008*\"miner\" + 0.007*\"flood\" + 0.007*\"afghan\" + 0.007*\"theft\" + 0.007*\"rais\" + 0.007*\"rain\" + 0.007*\"central\" + 0.007*\"costello\"\n",
            "Topic: 9 \n",
            "Words: 0.017*\"court\" + 0.016*\"charg\" + 0.013*\"murder\" + 0.013*\"assault\" + 0.012*\"face\" + 0.011*\"bali\" + 0.011*\"accus\" + 0.011*\"polic\" + 0.010*\"teen\" + 0.010*\"jail\"\n",
            "Topic: 10 \n",
            "Words: 0.013*\"tsunami\" + 0.012*\"soldier\" + 0.010*\"rat\" + 0.008*\"govern\" + 0.007*\"parliament\" + 0.007*\"growth\" + 0.006*\"law\" + 0.006*\"smoke\" + 0.006*\"tree\" + 0.006*\"kill\"\n",
            "Topic: 11 \n",
            "Words: 0.023*\"search\" + 0.021*\"miss\" + 0.011*\"woman\" + 0.010*\"polic\" + 0.009*\"condit\" + 0.008*\"riot\" + 0.007*\"croc\" + 0.007*\"resum\" + 0.007*\"lanka\" + 0.006*\"diseas\"\n",
            "Topic: 12 \n",
            "Words: 0.012*\"care\" + 0.010*\"solomon\" + 0.008*\"mother\" + 0.008*\"quak\" + 0.007*\"age\" + 0.007*\"wait\" + 0.006*\"slow\" + 0.006*\"limit\" + 0.006*\"philippin\" + 0.006*\"father\"\n",
            "Topic: 13 \n",
            "Words: 0.013*\"worri\" + 0.010*\"london\" + 0.009*\"mental\" + 0.009*\"victim\" + 0.008*\"liber\" + 0.008*\"mark\" + 0.007*\"polic\" + 0.007*\"chopper\" + 0.007*\"isra\" + 0.006*\"crash\"\n",
            "Topic: 14 \n",
            "Words: 0.008*\"indonesian\" + 0.008*\"export\" + 0.008*\"live\" + 0.008*\"educ\" + 0.007*\"welfar\" + 0.006*\"shop\" + 0.006*\"countri\" + 0.006*\"anim\" + 0.006*\"wheat\" + 0.006*\"aceh\"\n",
            "Topic: 15 \n",
            "Words: 0.012*\"highway\" + 0.011*\"wind\" + 0.010*\"hill\" + 0.010*\"farm\" + 0.010*\"speed\" + 0.008*\"strong\" + 0.008*\"break\" + 0.008*\"phone\" + 0.007*\"option\" + 0.007*\"swan\"\n",
            "Topic: 16 \n",
            "Words: 0.009*\"fish\" + 0.009*\"council\" + 0.009*\"rate\" + 0.008*\"govt\" + 0.008*\"plan\" + 0.007*\"chang\" + 0.007*\"station\" + 0.007*\"telstra\" + 0.006*\"budget\" + 0.006*\"illeg\"\n",
            "Topic: 17 \n",
            "Words: 0.009*\"govt\" + 0.008*\"hospit\" + 0.007*\"health\" + 0.007*\"abus\" + 0.007*\"councillor\" + 0.006*\"spend\" + 0.006*\"fund\" + 0.006*\"hobart\" + 0.006*\"cowboy\" + 0.006*\"access\"\n",
            "Topic: 18 \n",
            "Words: 0.015*\"coast\" + 0.014*\"fatal\" + 0.012*\"nuclear\" + 0.011*\"gold\" + 0.008*\"north\" + 0.008*\"iran\" + 0.007*\"crash\" + 0.007*\"hewitt\" + 0.007*\"senat\" + 0.007*\"lake\"\n",
            "Topic: 19 \n",
            "Words: 0.016*\"guilti\" + 0.012*\"plead\" + 0.010*\"emerg\" + 0.010*\"beazley\" + 0.007*\"marin\" + 0.006*\"newcastl\" + 0.006*\"northern\" + 0.006*\"cyclon\" + 0.006*\"policeman\" + 0.006*\"monitor\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4ugWpbO_QAz",
        "outputId": "b71afd98-f307-43a9-8474-17eaecf00c9b"
      },
      "source": [
        "processed_docs[4310]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ratepay', 'group', 'want', 'compulsori', 'local', 'govt', 'vote']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvrVqoNZ_VLB",
        "outputId": "91541c6b-f7d3-4c44-85fd-4b2ee55df318"
      },
      "source": [
        "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
        "  print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Score: 0.5599225759506226\t \n",
            "Topic: 0.027*\"plan\" + 0.017*\"nation\" + 0.016*\"urg\" + 0.016*\"hous\" + 0.015*\"public\" + 0.015*\"elect\" + 0.015*\"power\" + 0.014*\"continu\" + 0.014*\"govt\" + 0.013*\"council\"\n",
            "\n",
            "Score: 0.20732003450393677\t \n",
            "Topic: 0.023*\"fear\" + 0.017*\"push\" + 0.015*\"break\" + 0.014*\"worker\" + 0.014*\"famili\" + 0.013*\"fish\" + 0.012*\"telstra\" + 0.011*\"sale\" + 0.010*\"feder\" + 0.010*\"govt\"\n",
            "\n",
            "Score: 0.14525026082992554\t \n",
            "Topic: 0.036*\"charg\" + 0.034*\"court\" + 0.032*\"face\" + 0.021*\"accus\" + 0.020*\"jail\" + 0.017*\"murder\" + 0.016*\"drug\" + 0.016*\"case\" + 0.013*\"trial\" + 0.013*\"terror\"\n",
            "\n",
            "Score: 0.012503069825470448\t \n",
            "Topic: 0.034*\"council\" + 0.024*\"water\" + 0.021*\"boost\" + 0.017*\"plan\" + 0.014*\"offer\" + 0.012*\"fund\" + 0.012*\"chang\" + 0.012*\"govt\" + 0.010*\"delay\" + 0.010*\"welcom\"\n",
            "\n",
            "Score: 0.012502149678766727\t \n",
            "Topic: 0.018*\"concern\" + 0.017*\"govt\" + 0.016*\"protest\" + 0.015*\"school\" + 0.014*\"labor\" + 0.013*\"union\" + 0.012*\"defend\" + 0.010*\"inquiri\" + 0.010*\"bird\" + 0.010*\"plan\"\n",
            "\n",
            "Score: 0.01250147633254528\t \n",
            "Topic: 0.020*\"rise\" + 0.019*\"price\" + 0.018*\"say\" + 0.017*\"govt\" + 0.017*\"health\" + 0.014*\"farmer\" + 0.012*\"fund\" + 0.011*\"hospit\" + 0.011*\"fuel\" + 0.010*\"flood\"\n",
            "\n",
            "Score: 0.012500280514359474\t \n",
            "Topic: 0.018*\"home\" + 0.017*\"talk\" + 0.017*\"deal\" + 0.013*\"lose\" + 0.012*\"iraq\" + 0.012*\"north\" + 0.010*\"trade\" + 0.010*\"aust\" + 0.009*\"grower\" + 0.009*\"blue\"\n",
            "\n",
            "Score: 0.01250012218952179\t \n",
            "Topic: 0.015*\"coast\" + 0.015*\"year\" + 0.014*\"gold\" + 0.014*\"market\" + 0.013*\"open\" + 0.013*\"record\" + 0.010*\"world\" + 0.010*\"miner\" + 0.010*\"close\" + 0.010*\"storm\"\n",
            "\n",
            "Score: 0.012500063516199589\t \n",
            "Topic: 0.061*\"polic\" + 0.029*\"kill\" + 0.024*\"crash\" + 0.018*\"death\" + 0.016*\"investig\" + 0.016*\"miss\" + 0.016*\"attack\" + 0.015*\"probe\" + 0.013*\"bomb\" + 0.012*\"search\"\n",
            "\n",
            "Score: 0.012500006705522537\t \n",
            "Topic: 0.015*\"test\" + 0.014*\"win\" + 0.013*\"south\" + 0.012*\"australia\" + 0.012*\"lead\" + 0.010*\"clash\" + 0.010*\"commun\" + 0.010*\"final\" + 0.010*\"victori\" + 0.009*\"damag\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uJV0CLEAJQA",
        "outputId": "3024ec29-523e-471e-be07-acf8c960aac6"
      },
      "source": [
        "for index, score in sorted(lda_model_tfidf[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
        "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Score: 0.5791507363319397\t \n",
            "Topic: 0.011*\"govt\" + 0.011*\"fund\" + 0.011*\"health\" + 0.009*\"urg\" + 0.008*\"plan\" + 0.008*\"servic\" + 0.008*\"council\" + 0.007*\"boost\" + 0.006*\"indigen\" + 0.006*\"seek\"\n",
            "\n",
            "Score: 0.17746858298778534\t \n",
            "Topic: 0.009*\"miss\" + 0.009*\"blaze\" + 0.008*\"search\" + 0.007*\"firefight\" + 0.006*\"polic\" + 0.006*\"damag\" + 0.006*\"uranium\" + 0.004*\"corbi\" + 0.004*\"restrict\" + 0.004*\"crew\"\n",
            "\n",
            "Score: 0.155869722366333\t \n",
            "Topic: 0.017*\"charg\" + 0.016*\"polic\" + 0.012*\"court\" + 0.012*\"murder\" + 0.011*\"face\" + 0.007*\"assault\" + 0.007*\"investig\" + 0.007*\"jail\" + 0.006*\"death\" + 0.006*\"drug\"\n",
            "\n",
            "Score: 0.012503143399953842\t \n",
            "Topic: 0.008*\"council\" + 0.008*\"plan\" + 0.008*\"price\" + 0.007*\"govt\" + 0.007*\"market\" + 0.006*\"rise\" + 0.005*\"telstra\" + 0.005*\"concern\" + 0.004*\"chang\" + 0.004*\"urg\"\n",
            "\n",
            "Score: 0.012501470744609833\t \n",
            "Topic: 0.007*\"final\" + 0.006*\"open\" + 0.005*\"teacher\" + 0.005*\"hewitt\" + 0.004*\"wallabi\" + 0.004*\"wheat\" + 0.004*\"cole\" + 0.003*\"vail\" + 0.003*\"corrupt\" + 0.003*\"lead\"\n",
            "\n",
            "Score: 0.012501467019319534\t \n",
            "Topic: 0.016*\"kill\" + 0.011*\"bomb\" + 0.010*\"iraq\" + 0.008*\"attack\" + 0.007*\"iraqi\" + 0.007*\"soldier\" + 0.006*\"troop\" + 0.006*\"blast\" + 0.005*\"palestinian\" + 0.005*\"prison\"\n",
            "\n",
            "Score: 0.012501375749707222\t \n",
            "Topic: 0.006*\"plead\" + 0.006*\"miner\" + 0.006*\"guilti\" + 0.005*\"west\" + 0.004*\"gold\" + 0.004*\"coast\" + 0.004*\"pacif\" + 0.004*\"island\" + 0.003*\"plan\" + 0.003*\"polic\"\n",
            "\n",
            "Score: 0.012501255609095097\t \n",
            "Topic: 0.007*\"toll\" + 0.005*\"south\" + 0.005*\"cyclon\" + 0.004*\"north\" + 0.004*\"rise\" + 0.004*\"australia\" + 0.004*\"thousand\" + 0.004*\"death\" + 0.004*\"test\" + 0.004*\"aussi\"\n",
            "\n",
            "Score: 0.012501160614192486\t \n",
            "Topic: 0.019*\"crash\" + 0.009*\"road\" + 0.008*\"polic\" + 0.007*\"accid\" + 0.007*\"fatal\" + 0.007*\"die\" + 0.006*\"highway\" + 0.006*\"victim\" + 0.006*\"plane\" + 0.005*\"speed\"\n",
            "\n",
            "Score: 0.01250108890235424\t \n",
            "Topic: 0.010*\"closer\" + 0.007*\"drink\" + 0.007*\"tsunami\" + 0.006*\"bird\" + 0.006*\"drive\" + 0.005*\"bail\" + 0.005*\"refus\" + 0.005*\"japan\" + 0.004*\"hostag\" + 0.004*\"suspend\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRNLfrX0ANhY",
        "outputId": "3d656d57-bb1d-4e69-df8d-e0d450aa0a16"
      },
      "source": [
        "unseen_document = 'How a Pentagon deal became an identity crisis for Google'\n",
        "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
        "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.30419841408729553\t Topic: 0.018*\"home\" + 0.017*\"talk\" + 0.017*\"deal\" + 0.013*\"lose\" + 0.012*\"iraq\"\n",
            "Score: 0.21675674617290497\t Topic: 0.027*\"plan\" + 0.017*\"nation\" + 0.016*\"urg\" + 0.016*\"hous\" + 0.015*\"public\"\n",
            "Score: 0.19483689963817596\t Topic: 0.023*\"fear\" + 0.017*\"push\" + 0.015*\"break\" + 0.014*\"worker\" + 0.014*\"famili\"\n",
            "Score: 0.18420635163784027\t Topic: 0.015*\"coast\" + 0.015*\"year\" + 0.014*\"gold\" + 0.014*\"market\" + 0.013*\"open\"\n",
            "Score: 0.01666819117963314\t Topic: 0.018*\"concern\" + 0.017*\"govt\" + 0.016*\"protest\" + 0.015*\"school\" + 0.014*\"labor\"\n",
            "Score: 0.016666719689965248\t Topic: 0.020*\"rise\" + 0.019*\"price\" + 0.018*\"say\" + 0.017*\"govt\" + 0.017*\"health\"\n",
            "Score: 0.01666666939854622\t Topic: 0.061*\"polic\" + 0.029*\"kill\" + 0.024*\"crash\" + 0.018*\"death\" + 0.016*\"investig\"\n",
            "Score: 0.01666666753590107\t Topic: 0.036*\"charg\" + 0.034*\"court\" + 0.032*\"face\" + 0.021*\"accus\" + 0.020*\"jail\"\n",
            "Score: 0.01666666753590107\t Topic: 0.034*\"council\" + 0.024*\"water\" + 0.021*\"boost\" + 0.017*\"plan\" + 0.014*\"offer\"\n",
            "Score: 0.01666666753590107\t Topic: 0.015*\"test\" + 0.014*\"win\" + 0.013*\"south\" + 0.012*\"australia\" + 0.012*\"lead\"\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}